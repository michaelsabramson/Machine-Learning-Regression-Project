{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing necessary libraries for data analysis including dataframe, graphing, and modeling tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "#must install catboost with pip\n",
    "#pip install catboost --no-cache-dir\n",
    "import pandas as pd # data science essentials\n",
    "import seaborn as sns # data visualization\n",
    "import matplotlib.pyplot as plt # data visualization\n",
    "import statsmodels.formula.api as smf # linear regression (statsmodels)\n",
    "from sklearn.model_selection import train_test_split # train/test split\n",
    "from sklearn.linear_model import LinearRegression # linear regression (scikit-learn)\n",
    "import numpy as np #log and math tools\n",
    "from sklearn.linear_model import Ridge #ridge regression\n",
    "from sklearn.linear_model import Lasso #lasso regression\n",
    "import sklearn.linear_model #contains ARD regression\n",
    "from catboost import CatBoostRegressor #best gradient regression package\n",
    "from contextlib import contextmanager #first package for output suppression\n",
    "import sys, os #second package for output suppression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the data set for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#locating dataset\n",
    "file = 'Apprentice_Chef_Dataset.xlsx'\n",
    "\n",
    "#reading dataset into a dataframe\n",
    "dataset = pd.read_excel(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Histograms for outlier analysis. Histograms reveal information about normalcy of variables as well as distribution of categorical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepares dataset for histogram creation, removes non-numerical or non-continuous variables\n",
    "histset = dataset.drop(['REVENUE',\n",
    "                           'NAME',\n",
    "                           'EMAIL',\n",
    "                           'FIRST_NAME',\n",
    "                           'FAMILY_NAME',\n",
    "                           'MOBILE_NUMBER'],\n",
    "                           axis = 1)\n",
    "\n",
    "#histset.hist( figsize = (10,100), bins=100, grid=False, layout=(23,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regression plots to examine explanatory variables' relationships with the response. This reveals possible candidates for log transformations and possible variables that should be removed from the regression. Possible outlier thresholds are also revealed in these plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preparing data for regplots\n",
    "regplots_df = dataset.drop(['NAME',\n",
    "                           'EMAIL',\n",
    "                           'FIRST_NAME',\n",
    "                           'FAMILY_NAME',\n",
    "                           'MOBILE_NUMBER'],\n",
    "                        axis = 1)\n",
    "\n",
    "#regplots for each variable vs revenue, must run one at a time and comment all others out\n",
    "#sns.regplot(x=regplots_df[\"WEEKLY_PLAN\"], y=regplots_df[\"REVENUE\"]) \n",
    "#sns.regplot(x=regplots_df[\"CROSS_SELL_SUCCESS\"], y=regplots_df[\"REVENUE\"]) \n",
    "#sns.regplot(x=regplots_df[\"TOTAL_PHOTOS_VIEWED\"], y=regplots_df[\"REVENUE\"]) \n",
    "#sns.regplot(x=regplots_df[\"AVG_CLICKS_PER_VISIT\"], y=regplots_df[\"REVENUE\"]) \n",
    "#sns.regplot(x=regplots_df[\"MEDIAN_MEAL_RATING\"], y=regplots_df[\"REVENUE\"]) \n",
    "#sns.regplot(x=regplots_df[\"MASTER_CLASSES_ATTENDED\"], y=regplots_df[\"REVENUE\"]) \n",
    "#sns.regplot(x=regplots_df[\"LARGEST_ORDER_SIZE\"], y=regplots_df[\"REVENUE\"]) \n",
    "#sns.regplot(x=regplots_df[\"AVG_PREP_VID_TIME\"], y=regplots_df[\"REVENUE\"])\n",
    "#sns.regplot(x=regplots_df[\"FOLLOWED_RECOMMENDATIONS_PCT\"], y=regplots_df[\"REVENUE\"]) \n",
    "#sns.regplot(x=regplots_df[\"REFRIGERATED_LOCKER\"], y=regplots_df[\"REVENUE\"]) \n",
    "#sns.regplot(x=regplots_df[\"PACKAGE_LOCKER\"], y=regplots_df[\"REVENUE\"]) \n",
    "#sns.regplot(x=regplots_df[\"LATE_DELIVERIES\"], y=regplots_df[\"REVENUE\"]) \n",
    "#sns.regplot(x=regplots_df[\"EARLY_DELIVERIES\"], y=regplots_df[\"REVENUE\"]) \n",
    "#sns.regplot(x=regplots_df[\"MOBILE_LOGINS\"], y=regplots_df[\"REVENUE\"]) \n",
    "#sns.regplot(x=regplots_df[\"PC_LOGINS\"], y=regplots_df[\"REVENUE\"])\n",
    "#sns.regplot(x=regplots_df[\"TASTES_AND_PREFERENCES\"], y=regplots_df[\"REVENUE\"])\n",
    "#sns.regplot(x=regplots_df[\"CANCELLATIONS_AFTER_NOON\"], y=regplots_df[\"REVENUE\"])\n",
    "#sns.regplot(x=regplots_df[\"CANCELLATIONS_BEFORE_NOON\"], y=regplots_df[\"REVENUE\"])\n",
    "#sns.regplot(x=regplots_df[\"AVG_TIME_PER_SITE_VISIT\"], y=regplots_df[\"REVENUE\"]) \n",
    "#sns.regplot(x=regplots_df[\"PRODUCT_CATEGORIES_VIEWED\"], y=regplots_df[\"REVENUE\"])     \n",
    "#sns.regplot(x=regplots_df[\"CONTACTS_W_CUSTOMER_SERVICE\"], y=regplots_df[\"REVENUE\"])\n",
    "#sns.regplot(x=regplots_df[\"UNIQUE_MEALS_PURCH\"], y=regplots_df[\"REVENUE\"])\n",
    "#sns.regplot(x=regplots_df[\"TOTAL_MEALS_ORDERED\"], y=regplots_df[\"REVENUE\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis of the histograms and regplots revealed outlier thresholds for 'AVG_PREP_VID_TIME', 'UNIQUE_MEALS_PURCH', 'TOTAL_MEALS_ORDERED', 'AVG_TIME_PER_SITE_VISIT', 'EARLY_DELIVERIES', 'AVG_PREP_VID_TIME', 'AVG_CLICKS_PER_VISIT', and 'LARGEST_ORDER_SIZE'. Analysis revealed log transformation in 'AVG_TIME_PER_SITE_VISIT' and 'TOTAL_PHOTOS_VIEWED'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next I examined a heatmap to look for high correlations between explanatory variables. Sometimes highly correlated explanatory variables either need to be removed or need to be given an interaction term such as variable1*variable2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set size of figure\n",
    "#plt.figure(figsize=(10,10))\n",
    "\n",
    "#heatmap\n",
    "#sns.heatmap(histset.corr())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next I moved onto testing various regression models to see which had the highest baseline performance with this dataset. In order to begin this phase in my analysis, I identified by my x and y variable data and did a train_test_split to create training and testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparing explanatory variable data\n",
    "chef_data   = dataset.drop(['REVENUE',\n",
    "                           'NAME',\n",
    "                           'EMAIL',\n",
    "                           'FIRST_NAME',\n",
    "                           'FAMILY_NAME',\n",
    "                           'MOBILE_NUMBER'],\n",
    "                           axis = 1)\n",
    "\n",
    "# preparing response variable data\n",
    "chef_target = dataset.loc[:, 'REVENUE']\n",
    "\n",
    "# preparing training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "            chef_data,\n",
    "            chef_target,\n",
    "            test_size = 0.25,\n",
    "            random_state = 222)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next I moved on to preparing and executing my linear regression. First I used statsmodels to get an R^2 and then I use sklearn to fit and predict a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# declaring set of x-variables\n",
    "x_variables = chef_data.columns\n",
    "\n",
    "# looping to make x-variables suitable for statsmodels\n",
    "#for val in x_variables:\n",
    "    #print(f\"chef_train['{val}'] +\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merging X_train and y_train so that they can be used in statsmodels\n",
    "chef_train = pd.concat([X_train, y_train], axis = 1)\n",
    "\n",
    "\n",
    "# Step 1: build a model\n",
    "lm_best = smf.ols(formula =  \"\"\"REVENUE ~chef_train['CROSS_SELL_SUCCESS'] +\n",
    "                                            chef_train['TOTAL_MEALS_ORDERED'] +\n",
    "                                            chef_train['UNIQUE_MEALS_PURCH'] +\n",
    "                                            chef_train['CONTACTS_W_CUSTOMER_SERVICE'] +\n",
    "                                            chef_train['PRODUCT_CATEGORIES_VIEWED'] +\n",
    "                                            chef_train['AVG_TIME_PER_SITE_VISIT'] +\n",
    "                                            chef_train['CANCELLATIONS_BEFORE_NOON'] +\n",
    "                                            chef_train['CANCELLATIONS_AFTER_NOON'] +\n",
    "                                            chef_train['TASTES_AND_PREFERENCES'] +\n",
    "                                            chef_train['PC_LOGINS'] +\n",
    "                                            chef_train['MOBILE_LOGINS'] +\n",
    "                                            chef_train['WEEKLY_PLAN'] +\n",
    "                                            chef_train['EARLY_DELIVERIES'] +\n",
    "                                            chef_train['LATE_DELIVERIES'] +\n",
    "                                            chef_train['PACKAGE_LOCKER'] +\n",
    "                                            chef_train['REFRIGERATED_LOCKER'] +\n",
    "                                            chef_train['FOLLOWED_RECOMMENDATIONS_PCT'] +\n",
    "                                            chef_train['AVG_PREP_VID_TIME'] +\n",
    "                                            chef_train['LARGEST_ORDER_SIZE'] +\n",
    "                                            chef_train['MASTER_CLASSES_ATTENDED'] +\n",
    "                                            chef_train['MEDIAN_MEAL_RATING'] +\n",
    "                                            chef_train['AVG_CLICKS_PER_VISIT'] +\n",
    "                                            chef_train['TOTAL_PHOTOS_VIEWED']\"\"\",\n",
    "                                            data = chef_train)\n",
    "\n",
    "\n",
    "# Step 2: fit the model based on the data\n",
    "results = lm_best.fit()\n",
    "\n",
    "# Step 3: analyze the summary output. uncomment out the print statement below for a summary with R^2 for the linear regression\n",
    "#print(results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next I instantiated, fit, and predicted my standard linear regression model. I saved and printed the test and train scores for this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.6603\n",
      "Testing Score: 0.5642\n"
     ]
    }
   ],
   "source": [
    "# INSTANTIATING a model object\n",
    "lr = LinearRegression()\n",
    "\n",
    "\n",
    "# FITTING to the training data\n",
    "lr_fit = lr.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# PREDICTING on new data\n",
    "lr_pred = lr_fit.predict(X_test)\n",
    "\n",
    "\n",
    "# SCORING the results\n",
    "#print('Training Score:', lr.score(X_train, y_train).round(4))\n",
    "#print('Testing Score:',  lr.score(X_test, y_test).round(4))\n",
    "\n",
    "# saving scoring data for future use\n",
    "lr_train_score = lr.score(X_train, y_train).round(4)\n",
    "lr_test_score  = lr.score(X_test, y_test).round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next I instantiated, fit, and predicted my ridge regression model. I also saved and printed these results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSTANTIATING a model object\n",
    "ridge_model = Ridge()\n",
    "\n",
    "# FITTING the training data\n",
    "ridge_fit = ridge_model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# PREDICTING on new data\n",
    "ridge_pred = ridge_model.predict(X_test)\n",
    "\n",
    "#print('Training Score:', ridge_model.score(X_train, y_train).round(4))\n",
    "#print('Testing Score:',  ridge_model.score(X_test, y_test).round(4))\n",
    "\n",
    "\n",
    "# saving scoring data for future use\n",
    "ridge_train_score = ridge_model.score(X_train, y_train).round(4)\n",
    "ridge_test_score  = ridge_model.score(X_test, y_test).round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next I instantiated, fit, and predicted my lasso regression model. I also saved and printed these results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSTANTIATING a model object\n",
    "lasso_model = Lasso()\n",
    "\n",
    "# FITTING the training data\n",
    "lasso_fit = lasso_model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# PREDICTING on new data\n",
    "lasso_pred = lasso_model.predict(X_test)\n",
    "\n",
    "#print('Training Score:', lasso_model.score(X_train, y_train).round(4))\n",
    "#print('Testing Score:',  lasso_model.score(X_test, y_test).round(4))\n",
    "\n",
    "\n",
    "# saving scoring data for future use\n",
    "lasso_train_score = lasso_model.score(X_train, y_train).round(4)\n",
    "lasso_test_score  = lasso_model.score(X_test, y_test).round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next I instantiated, fit, and predicted my ARD regression model. Once again I saved and printed these results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSTANTIATING a model object\n",
    "ard_model = sklearn.linear_model.ARDRegression()\n",
    "\n",
    "\n",
    "# FITTING the training data\n",
    "ard_fit = ard_model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# PREDICTING on new data\n",
    "ard_pred = ard_model.predict(X_test)\n",
    "\n",
    "\n",
    "#print('Training Score:', ard_model.score(X_train, y_train).round(4))\n",
    "#print('Testing Score:',  ard_model.score(X_test, y_test).round(4))\n",
    "\n",
    "\n",
    "# saving scoring data for future use\n",
    "ard_train_score = ard_model.score(X_train, y_train).round(4)\n",
    "ard_test_score  = ard_model.score(X_test, y_test).round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I tried my CatBoostRegression. As always, I print and save my results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for suppressing unnecessary iteration output\n",
    "@contextmanager\n",
    "def suppress_stdout():\n",
    "    with open(os.devnull, \"w\") as devnull:\n",
    "        old_stdout = sys.stdout\n",
    "        sys.stdout = devnull\n",
    "        try:  \n",
    "            yield\n",
    "        finally:\n",
    "            sys.stdout = old_stdout\n",
    "\n",
    "# INSTANTIATING a model object with chosen hyperparamaters\n",
    "cat_model = CatBoostRegressor(learning_rate=.01,iterations=4000,depth = 6,  cat_features = [0,8,14,15], l2_leaf_reg=6,thread_count=4,\n",
    "                             border_count=50)\n",
    "\n",
    "with suppress_stdout():\n",
    "    # FITTING the training data\n",
    "    cat_fit = cat_model.fit(X_train, y_train,\n",
    "                           use_best_model=True,\n",
    "                          eval_set= (X_test, y_test))\n",
    "\n",
    "\n",
    "    # PREDICTING on new data\n",
    "    cat_pred = cat_model.predict(X_test)\n",
    "\n",
    "# saving scoring data for future use\n",
    "cat_train_score = cat_model.score(X_train, y_train).round(4)\n",
    "cat_test_score  = cat_model.score(X_test, y_test).round(4)\n",
    "\n",
    "#print('Training Score:', cat_model.score(X_train, y_train).round(4))\n",
    "#print('Testing Score:',  cat_model.score(X_test, y_test).round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next I compared the results of these models and selected my final model type which I would tweak based on the findings in this analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model      Train Score      Test Score\n",
      "-----      -----------      ----------\n",
      "OLS        0.6603           0.5642\n",
      "Ridge      0.6603           0.5643\n",
      "Lasso      0.6603           0.5645\n",
      "ARD        0.6586           0.5665\n",
      "Cat        0.9732           0.7912\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# comparing results\n",
    "\n",
    "print(f\"\"\"\n",
    "Model      Train Score      Test Score\n",
    "-----      -----------      ----------\n",
    "OLS        {lr_train_score}           {lr_test_score}\n",
    "Ridge      {ridge_train_score}           {ridge_test_score}\n",
    "Lasso      {lasso_train_score}           {lasso_test_score}\n",
    "ARD        {ard_train_score}           {ard_test_score}\n",
    "Cat        {cat_train_score}           {cat_test_score}\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "# creating a dictionary for model results\n",
    "model_performance = {'Model'    : ['OLS', 'Ridge', 'Lasso', 'ARD', 'Cat'],\n",
    "           \n",
    "                     'Training' : [lr_train_score, ridge_train_score,\n",
    "                                   lasso_train_score, ard_train_score, cat_train_score],\n",
    "           \n",
    "                     'Testing'  : [lr_test_score, ridge_test_score,\n",
    "                                   lasso_test_score, ard_test_score, cat_test_score]}\n",
    "\n",
    "\n",
    "# converting model_performance into a DataFrame\n",
    "model_performance = pd.DataFrame(model_performance)\n",
    "\n",
    "\n",
    "# sending model results to Excel\n",
    "model_performance.to_excel('regression_model_performance.xlsx',\n",
    "                           index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I chose to use CatBoostRegression which is a form of gradient boost regression.                     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below I will show a number of variables that I created and tested. For the most part, these variables increase the test scores of linear, ridge, lasso, and ARD regressions but do not increase the score of my Cat regression. Additionally, the Cat regression test score remains higher despite the increases in the test scores of the other regressions. Therefore, I stuck with Cat for my final model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I tried creating a series of categorical variables to mark turning points in revenue trends for the following variables\n",
    "#contacts with customer service > 10 marks a turning point in trend\n",
    "#dataset['CWCSover10'] = [1 if x >10 else 0 for x in dataset['CONTACTS_W_CUSTOMER_SERVICE']]\n",
    "\n",
    "#clicksover15 marks a turning point in trend\n",
    "#dataset['Clicksover15'] = [1 if x >15 else 0 for x in dataset['AVG_CLICKS_PER_VISIT']]\n",
    "\n",
    "#clicksover15 marks a turning point in trend\n",
    "#dataset['latedeliveriesover13'] = [1 if x >13 else 0 for x in dataset['LATE_DELIVERIES']]\n",
    "\n",
    "#dummy variable for mobile logins trend threshold\n",
    "#dataset['mobilecat'] = [1 if x == 1 or x==2 else 0 for x in dataset['MOBILE_LOGINS']]\n",
    "\n",
    "#dummyvariable for unique meals purchased trend threshold\n",
    "#dataset['uniquecat'] = [1 if x>9.5 else 0 for x in dataset['UNIQUE_MEALS_PURCH']]\n",
    "\n",
    "#I tried one hot encoding median meal rating\n",
    "#dataset = pd.concat([dataset, pd.get_dummies(dataset['MEDIAN_MEAL_RATING'])],axis=1)\n",
    "#dataset.columns = [                     'REVENUE',           'CROSS_SELL_SUCCESS',\n",
    "#                               'NAME',                        'EMAIL',\n",
    "#                         'FIRST_NAME',                  'FAMILY_NAME',\n",
    "#                'TOTAL_MEALS_ORDERED',           'UNIQUE_MEALS_PURCH',\n",
    "#        'CONTACTS_W_CUSTOMER_SERVICE',    'PRODUCT_CATEGORIES_VIEWED',\n",
    "#            'AVG_TIME_PER_SITE_VISIT',                'MOBILE_NUMBER',\n",
    "#          'CANCELLATIONS_BEFORE_NOON',     'CANCELLATIONS_AFTER_NOON',\n",
    "#            'TASTES_AND_PREFERENCES',                    'PC_LOGINS',\n",
    "#                      'MOBILE_LOGINS',                  'WEEKLY_PLAN',\n",
    "#                   'EARLY_DELIVERIES',              'LATE_DELIVERIES',\n",
    "#                     'PACKAGE_LOCKER',          'REFRIGERATED_LOCKER',\n",
    "#       'FOLLOWED_RECOMMENDATIONS_PCT',            'AVG_PREP_VID_TIME',\n",
    "#                 'LARGEST_ORDER_SIZE',      'MASTER_CLASSES_ATTENDED',\n",
    "#                 'MEDIAN_MEAL_RATING',         'AVG_CLICKS_PER_VISIT',\n",
    "#                'TOTAL_PHOTOS_VIEWED',                   'CWCSover10',\n",
    "#                       'Clicksover15',         'latedeliveriesover13',\n",
    "#                          'mobilecat',                    'uniquecat',\n",
    "#                           'rating_1',                     'rating_2',\n",
    "#                           'rating_3',                     'rating_4',\n",
    "#                           'rating_5']\n",
    "\n",
    "#I tried one hot encoding masters classes attended\n",
    "#dataset = pd.concat([dataset, pd.get_dummies(dataset['MASTER_CLASSES_ATTENDED'])],axis=1)\n",
    "#dataset.columns = [                     'REVENUE',           'CROSS_SELL_SUCCESS',\n",
    "#                               'NAME',                        'EMAIL',\n",
    "#                         'FIRST_NAME',                  'FAMILY_NAME',\n",
    "#                'TOTAL_MEALS_ORDERED',           'UNIQUE_MEALS_PURCH',\n",
    "#        'CONTACTS_W_CUSTOMER_SERVICE',    'PRODUCT_CATEGORIES_VIEWED',\n",
    "#            'AVG_TIME_PER_SITE_VISIT',                'MOBILE_NUMBER',\n",
    "#          'CANCELLATIONS_BEFORE_NOON',     'CANCELLATIONS_AFTER_NOON',\n",
    "#             'TASTES_AND_PREFERENCES',                    'PC_LOGINS',\n",
    "#                      'MOBILE_LOGINS',                  'WEEKLY_PLAN',\n",
    "#                   'EARLY_DELIVERIES',              'LATE_DELIVERIES',\n",
    "#                     'PACKAGE_LOCKER',          'REFRIGERATED_LOCKER',\n",
    "#       'FOLLOWED_RECOMMENDATIONS_PCT',            'AVG_PREP_VID_TIME',\n",
    "#                 'LARGEST_ORDER_SIZE',      'MASTER_CLASSES_ATTENDED',\n",
    "#                 'MEDIAN_MEAL_RATING',         'AVG_CLICKS_PER_VISIT',\n",
    "#                'TOTAL_PHOTOS_VIEWED',                   'CWCSover10',\n",
    "#                       'Clicksover15',         'latedeliveriesover13',\n",
    "#                          'mobilecat',                    'uniquecat',\n",
    "#                           'rating_1',                     'rating_2',\n",
    "#                           'rating_3',                     'rating_4',\n",
    "#                           'rating_5',                      'class_0',\n",
    "#                            'class_1',                      'class_2',\n",
    "#                            'class_3']\n",
    "\n",
    "#I tried splitting email into domain addresses and one hot encoding this variable into cateogricals for each domain\n",
    "#dataset['domain'] = dataset['EMAIL'].str.split('@').str[1]\n",
    "#dataset = pd.concat([dataset, pd.get_dummies(dataset['domain'])],axis=1)\n",
    "\n",
    "#this loop creates interaction terms between every explanatory variable\n",
    "#this helped for linear, lasso, ridge, and ARD but did not help for Cat\n",
    "#L=[(x, y) for x, y in itertools.product(chef_data.columns,chef_data.columns) if x != y]\n",
    "#interaction_data = pd.concat([pd.DataFrame({''.join(i):chef_data.loc[:,i].prod(axis=1)}) for i in L],axis=1)\n",
    "#chef_data = pd.concat([chef_data, interaction_data], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                            .O°o. .o°O________________________________O°o. .o°O.\n",
    "                            .°o.O.o° ¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯.°o.O.o°\n",
    "                            ░░░░░╔══╦╗░░░░╔╗░░░░░░╔╗╔╗░░░░░░░░\n",
    "                            ░░░░░╚╗╔╣╚╦═╦═╣║╔╗░░░░║║║╠═╦╦╗░░░░\n",
    "                            ░░░░░░║║║║╠╝║║║╠╝║░░░░║╚╝║║║║║░░░░\n",
    "                            ░░░░░░║║║║║║║║║╔╗╣░░░░╚╗╔╣║║║║░░░░\n",
    "                            ░░░░░░╚╝╚╩╩═╩╩╩╝╚╝░░░░░╚╝╚═╩═╝░░░░\n",
    "                            .O°o. .o°O________________________________O°o. .o°O.\n",
    "                            .°o.O.o° ¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯.°o.O.o°.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
